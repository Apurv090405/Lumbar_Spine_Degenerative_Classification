{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":206722223,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-12-10T10:23:34.520734Z","iopub.execute_input":"2024-12-10T10:23:34.521015Z","iopub.status.idle":"2024-12-10T10:23:44.694555Z","shell.execute_reply.started":"2024-12-10T10:23:34.520986Z","shell.execute_reply":"2024-12-10T10:23:44.693735Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.48-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.3.48-py3-none-any.whl (898 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m898.8/898.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.48 ultralytics-thop-2.0.13\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np \nimport pandas as pd \n\nimport cv2\nimport pydicom\nfrom PIL import Image\nfrom IPython.display import Image as IPyImage, display\n\nimport os\nimport re\nimport glob\nimport random\nfrom tqdm import tqdm\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"whitegrid\")\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom sklearn.model_selection import train_test_split\n\nfrom torchvision import transforms\nimport timm\n\nimport yaml\n\nimport albumentations as A\n\nfrom sklearn.model_selection import KFold\n\nfrom ultralytics import YOLO","metadata":{"execution":{"iopub.status.busy":"2024-12-10T10:23:44.696332Z","iopub.execute_input":"2024-12-10T10:23:44.696602Z","iopub.status.idle":"2024-12-10T10:23:51.981753Z","shell.execute_reply.started":"2024-12-10T10:23:44.696577Z","shell.execute_reply":"2024-12-10T10:23:51.981115Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\nlabel_coords_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv')\nseries_desc_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv')","metadata":{"execution":{"iopub.status.busy":"2024-12-10T10:23:51.982663Z","iopub.execute_input":"2024-12-10T10:23:51.983075Z","iopub.status.idle":"2024-12-10T10:23:52.114104Z","shell.execute_reply.started":"2024-12-10T10:23:51.983048Z","shell.execute_reply":"2024-12-10T10:23:52.113145Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Getting a list of all the study IDs and paths to their images\nimages_dir_path = r'/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\nstudy_id_list = os.listdir(images_dir_path)\nstudy_id_paths = [(x, f\"{images_dir_path}/{x}\") for x in study_id_list]\n\n# Initialize the metadata dictionary\nmeta_df = {}\n\n# Process each study and its series\nfor study_id, study_folder_path in study_id_paths:\n    series_ids = []\n    series_descriptions = []\n    \n    # Get all the series IDs (folders) within the study folder\n    try:\n        series_folders = os.listdir(study_folder_path)\n    except FileNotFoundError as e:\n        print(f\"Error: Folder not found for study {study_id}. Skipping this study.\")\n        continue  # Skip this study if the folder doesn't exist\n\n    # Process each series in the study folder\n    for series_id in series_folders:\n        try:\n            # Fetch the series description from the dataframe\n            series_description = series_desc_df[series_desc_df['series_id'] == int(series_id)]['series_description'].iloc[0]\n        except (IndexError, ValueError):\n            # Handle cases where series_id is not found in the dataframe or can't be converted to int\n            series_description = 'Unknown'\n\n        # Append series ID and description to the lists\n        series_ids.append(series_id)\n        series_descriptions.append(series_description)\n    \n    # Add metadata for the current study_id\n    meta_df[int(study_id)] = {\n        'folder_path': study_folder_path,\n        'series_ids': series_ids,\n        'series_descriptions': series_descriptions\n    }","metadata":{"execution":{"iopub.status.busy":"2024-12-10T10:23:52.116033Z","iopub.execute_input":"2024-12-10T10:23:52.116356Z","iopub.status.idle":"2024-12-10T10:24:00.502987Z","shell.execute_reply.started":"2024-12-10T10:23:52.116327Z","shell.execute_reply":"2024-12-10T10:24:00.502019Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def add_desc(df, meta_df):\n    df['series_desc'] = None\n\n    # Iterate over rows in the dataframe\n    for idx, coor_row in df.iterrows():\n        try:\n            # Find the meta_df for the study_id\n            meta_info = meta_df[int(coor_row['study_id'])]\n\n            # Find the index of the series_id in the meta_info\n            series_index = meta_info['series_ids'].index(str(coor_row['series_id']))\n\n            # Get the corresponding series description\n            series_desc = meta_info['series_descriptions'][series_index]\n\n            # Update the series_desc column\n            df.at[idx, 'series_desc'] = series_desc\n\n        except KeyError:\n            print(f\"Error processing study_id: {coor_row['study_id']} - Study ID not found in meta_df\")\n            df.at[idx, 'series_desc'] = 'Unknown'\n        except ValueError:\n            print(f\"Error processing study_id: {coor_row['study_id']} - Series ID not found in meta_df\")\n            df.at[idx, 'series_desc'] = 'Unknown'\n        except Exception as e:\n            print(f\"Error processing study_id: {coor_row['study_id']} - {e}\")\n            df.at[idx, 'series_desc'] = 'Unknown'\n    \n    return df\n\n# Apply the function\ncoords_with_desc = label_coords_df.copy()\ncoords_with_desc = add_desc(coords_with_desc, meta_df)\ncoords_with_desc.head(20)","metadata":{"execution":{"iopub.status.busy":"2024-12-10T10:24:00.504264Z","iopub.execute_input":"2024-12-10T10:24:00.504614Z","iopub.status.idle":"2024-12-10T10:24:03.452487Z","shell.execute_reply.started":"2024-12-10T10:24:00.504570Z","shell.execute_reply":"2024-12-10T10:24:03.451654Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    study_id   series_id  instance_number                         condition  \\\n0    4003253   702807833                8             Spinal Canal Stenosis   \n1    4003253   702807833                8             Spinal Canal Stenosis   \n2    4003253   702807833                8             Spinal Canal Stenosis   \n3    4003253   702807833                8             Spinal Canal Stenosis   \n4    4003253   702807833                8             Spinal Canal Stenosis   \n5    4003253  1054713880                4  Right Neural Foraminal Narrowing   \n6    4003253  1054713880                4  Right Neural Foraminal Narrowing   \n7    4003253  1054713880                5  Right Neural Foraminal Narrowing   \n8    4003253  1054713880                6  Right Neural Foraminal Narrowing   \n9    4003253  1054713880                6  Right Neural Foraminal Narrowing   \n10   4003253  1054713880               11   Left Neural Foraminal Narrowing   \n11   4003253  1054713880               11   Left Neural Foraminal Narrowing   \n12   4003253  1054713880               11   Left Neural Foraminal Narrowing   \n13   4003253  1054713880               12   Left Neural Foraminal Narrowing   \n14   4003253  1054713880               12   Left Neural Foraminal Narrowing   \n15   4003253  2448190387                3        Left Subarticular Stenosis   \n16   4003253  2448190387                4       Right Subarticular Stenosis   \n17   4003253  2448190387               11        Left Subarticular Stenosis   \n18   4003253  2448190387               11       Right Subarticular Stenosis   \n19   4003253  2448190387               19        Left Subarticular Stenosis   \n\n    level           x           y       series_desc  \n0   L1/L2  322.831858  227.964602  Sagittal T2/STIR  \n1   L2/L3  320.571429  295.714286  Sagittal T2/STIR  \n2   L3/L4  323.030303  371.818182  Sagittal T2/STIR  \n3   L4/L5  335.292035  427.327434  Sagittal T2/STIR  \n4   L5/S1  353.415929  483.964602  Sagittal T2/STIR  \n5   L4/L5  187.961759  251.839388       Sagittal T1  \n6   L5/S1  198.240918  285.613767       Sagittal T1  \n7   L3/L4  187.227533  210.722753       Sagittal T1  \n8   L1/L2  194.569790  127.755258       Sagittal T1  \n9   L2/L3  191.632887  165.934990       Sagittal T1  \n10  L1/L2  196.070671  126.021201       Sagittal T1  \n11  L4/L5  186.504472  251.592129       Sagittal T1  \n12  L5/S1  197.100569  289.457306       Sagittal T1  \n13  L2/L3  191.321555  170.120141       Sagittal T1  \n14  L3/L4  187.878354  217.245081       Sagittal T1  \n15  L1/L2  179.126448  161.235521          Axial T2  \n16  L1/L2  145.288771  158.624642          Axial T2  \n17  L2/L3  180.979730  158.764479          Axial T2  \n18  L2/L3  145.900042  157.096466          Axial T2  \n19  L3/L4  176.037645  157.528958          Axial T2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>series_id</th>\n      <th>instance_number</th>\n      <th>condition</th>\n      <th>level</th>\n      <th>x</th>\n      <th>y</th>\n      <th>series_desc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L1/L2</td>\n      <td>322.831858</td>\n      <td>227.964602</td>\n      <td>Sagittal T2/STIR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L2/L3</td>\n      <td>320.571429</td>\n      <td>295.714286</td>\n      <td>Sagittal T2/STIR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L3/L4</td>\n      <td>323.030303</td>\n      <td>371.818182</td>\n      <td>Sagittal T2/STIR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L4/L5</td>\n      <td>335.292035</td>\n      <td>427.327434</td>\n      <td>Sagittal T2/STIR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L5/S1</td>\n      <td>353.415929</td>\n      <td>483.964602</td>\n      <td>Sagittal T2/STIR</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>4</td>\n      <td>Right Neural Foraminal Narrowing</td>\n      <td>L4/L5</td>\n      <td>187.961759</td>\n      <td>251.839388</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>4</td>\n      <td>Right Neural Foraminal Narrowing</td>\n      <td>L5/S1</td>\n      <td>198.240918</td>\n      <td>285.613767</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>5</td>\n      <td>Right Neural Foraminal Narrowing</td>\n      <td>L3/L4</td>\n      <td>187.227533</td>\n      <td>210.722753</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>6</td>\n      <td>Right Neural Foraminal Narrowing</td>\n      <td>L1/L2</td>\n      <td>194.569790</td>\n      <td>127.755258</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>6</td>\n      <td>Right Neural Foraminal Narrowing</td>\n      <td>L2/L3</td>\n      <td>191.632887</td>\n      <td>165.934990</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>11</td>\n      <td>Left Neural Foraminal Narrowing</td>\n      <td>L1/L2</td>\n      <td>196.070671</td>\n      <td>126.021201</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>11</td>\n      <td>Left Neural Foraminal Narrowing</td>\n      <td>L4/L5</td>\n      <td>186.504472</td>\n      <td>251.592129</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>11</td>\n      <td>Left Neural Foraminal Narrowing</td>\n      <td>L5/S1</td>\n      <td>197.100569</td>\n      <td>289.457306</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>12</td>\n      <td>Left Neural Foraminal Narrowing</td>\n      <td>L2/L3</td>\n      <td>191.321555</td>\n      <td>170.120141</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4003253</td>\n      <td>1054713880</td>\n      <td>12</td>\n      <td>Left Neural Foraminal Narrowing</td>\n      <td>L3/L4</td>\n      <td>187.878354</td>\n      <td>217.245081</td>\n      <td>Sagittal T1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>3</td>\n      <td>Left Subarticular Stenosis</td>\n      <td>L1/L2</td>\n      <td>179.126448</td>\n      <td>161.235521</td>\n      <td>Axial T2</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>4</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L1/L2</td>\n      <td>145.288771</td>\n      <td>158.624642</td>\n      <td>Axial T2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>11</td>\n      <td>Left Subarticular Stenosis</td>\n      <td>L2/L3</td>\n      <td>180.979730</td>\n      <td>158.764479</td>\n      <td>Axial T2</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>11</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L2/L3</td>\n      <td>145.900042</td>\n      <td>157.096466</td>\n      <td>Axial T2</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>4003253</td>\n      <td>2448190387</td>\n      <td>19</td>\n      <td>Left Subarticular Stenosis</td>\n      <td>L3/L4</td>\n      <td>176.037645</td>\n      <td>157.528958</td>\n      <td>Axial T2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"sagt1_df = coords_with_desc[coords_with_desc['series_desc'] == 'Sagittal T1'].copy()\nsagt2_df = coords_with_desc[coords_with_desc['series_desc'] == 'Sagittal T2/STIR'].copy()\naxialt2_df = coords_with_desc[coords_with_desc['series_desc'] == 'Axial T2'].copy()","metadata":{"execution":{"iopub.status.busy":"2024-12-10T10:24:03.453635Z","iopub.execute_input":"2024-12-10T10:24:03.454347Z","iopub.status.idle":"2024-12-10T10:24:03.476743Z","shell.execute_reply.started":"2024-12-10T10:24:03.454307Z","shell.execute_reply":"2024-12-10T10:24:03.476171Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class SagT2_YOLO:\n    def __init__(self, df, images_dir, output_dir, img_size=384):\n        \"\"\"\n        Initialize Sagittal T2/STIR YOLO detector\n        Args:\n            df: DataFrame with annotations\n            images_dir: Path to DICOM images\n            output_dir: Path to save processed dataset\n            img_size: Target image size for YOLO\n        \"\"\"\n        self.df = df\n        self.images_dir = images_dir\n        self.output_dir = output_dir\n        self.img_size = img_size\n        \n        # Create initial directory structure\n        self.create_dataset_structure()\n        \n        # Process dataset\n        self.instance_coords_df = self.process_instance_coordinates()\n        self.processed_df = self.process_spine_dataset()\n        \n        # Create YAML and train model\n        self.yaml_path = self.create_dataset_yaml()\n        self.model, self.results = self.train_yolo()\n\n    def create_dataset_structure(self):\n        \"\"\"Create YOLO dataset directory structure\"\"\"\n        for split in ['train', 'val']:\n            for subdir in ['images', 'labels']:\n                path = os.path.join(self.output_dir, split, subdir)\n                os.makedirs(path, exist_ok=True)\n\n    def process_instance_coordinates(self):\n        \"\"\"\n        Process coordinates for Sagittal T2 images with coordinate sharing across instances\n        Returns DataFrame with coordinates for all instances, sharing information across the series\n        \"\"\"\n        result_records = []\n\n        # Group by series to process related instances\n        for (study_id, series_id), series_data in self.df.groupby(['study_id', 'series_id']):\n            # First, collect all coordinates for each level in the series\n            series_level_coords = {}\n            for level in ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']:\n                level_data = series_data[series_data['level'] == level]\n\n                if not level_data.empty:\n                    coords = []\n                    instances_with_data = set()  # Track which instances have data for this level\n\n                    for _, row in level_data.iterrows():\n                        instances_with_data.add(row['instance_number'])\n                        coords.append((row['x'], row['y']))\n\n                    # Calculate average coordinates for this level\n                    if coords:\n                        avg_x = np.mean([x for x, _ in coords])\n                        avg_y = np.mean([y for _, y in coords])\n                        \n                        series_level_coords[level] = {\n                            'instances': instances_with_data,\n                            'coords': (avg_x, avg_y),\n                            'original_coords': coords  # Keep original coordinates for reference\n                        }\n\n            # Get all unique instance numbers in the series\n            all_instances = series_data['instance_number'].unique()\n\n            # Create records for each instance\n            for instance_number in all_instances:\n                instance_data = series_data[series_data['instance_number'] == instance_number]\n                \n                record = {\n                    'study_id': study_id,\n                    'series_id': series_id,\n                    'instance_number': instance_number,\n                    'coordinate_sources': {}  # Track where coordinates came from\n                }\n\n                # Process each spinal level\n                for level in ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']:\n                    level_key = level.replace('/', '_').lower()\n                    \n                    # Check if this instance has original coordinates for this level\n                    instance_level_data = instance_data[instance_data['level'] == level]\n                    \n                    if not instance_level_data.empty:\n                        # Use original coordinates for this instance\n                        x = instance_level_data.iloc[0]['x']\n                        y = instance_level_data.iloc[0]['y']\n                        record['coordinate_sources'][level_key] = 'original'\n                    elif level in series_level_coords:\n                        # Use shared coordinates from series\n                        x, y = series_level_coords[level]['coords']\n                        record['coordinate_sources'][level_key] = 'shared'\n                    else:\n                        # No coordinates available\n                        x = y = None\n                        record['coordinate_sources'][level_key] = 'missing'\n                    \n                    record[f'{level_key}_x'] = x\n                    record[f'{level_key}_y'] = y\n\n                result_records.append(record)\n\n        # Convert to DataFrame\n        result_df = pd.DataFrame(result_records)\n\n        # Add metadata about coordinate availability\n        result_df['available_levels'] = result_df.apply(\n            lambda row: [\n                level for level in ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']\n                if not pd.isna(row[f\"{level.replace('/', '_').lower()}_x\"])\n            ],\n            axis=1\n        )\n        \n        result_df['total_levels'] = result_df['available_levels'].apply(len)\n\n        # Print statistics\n        print(\"\\nDataset Statistics:\")\n        print(f\"Total series processed: {len(result_df['series_id'].unique())}\")\n        print(f\"Total instances processed: {len(result_df)}\")\n        print(\"\\nLevel availability:\")\n        for level in ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']:\n            count = result_df[f'{level}_x'].notna().sum()\n            original_count = sum(result_df['coordinate_sources'].apply(\n                lambda x: x.get(level, '') == 'original'\n            ))\n            shared_count = sum(result_df['coordinate_sources'].apply(\n                lambda x: x.get(level, '') == 'shared'\n            ))\n            print(f\"{level}: {count} instances ({count/len(result_df)*100:.1f}%)\")\n            print(f\"  - Original: {original_count}\")\n            print(f\"  - Shared: {shared_count}\")\n\n        return result_df\n\n    def create_yolo_annotation(self, row, image_width, image_height):\n        \"\"\"Create YOLO format annotations for Sagittal T2 images\"\"\"\n        annotations = []\n        box_width = 0.05  # Relative box width\n        box_height = 0.05  # Relative box height\n        \n        level_map = {\n            'l1_l2': 0,\n            'l2_l3': 1,\n            'l3_l4': 2,\n            'l4_l5': 3,\n            'l5_s1': 4\n        }\n        \n        for level, idx in level_map.items():\n            x_coord = row.get(f'{level}_x')\n            y_coord = row.get(f'{level}_y')\n            \n            if pd.notna(x_coord) and pd.notna(y_coord):\n                x_norm = x_coord / image_width\n                y_norm = y_coord / image_height\n                annotations.append(f\"{idx} {x_norm:.6f} {y_norm:.6f} {box_width:.6f} {box_height:.6f}\")\n        \n        return annotations\n\n    def process_spine_dataset(self):\n        \"\"\"Process and save dataset in YOLO format\"\"\"\n        # Split studies\n        studies = self.instance_coords_df['study_id'].unique()\n        train_studies, val_studies = train_test_split(studies, train_size=0.8, random_state=42)\n        \n        processed_counts = {'train': 0, 'val': 0}\n        failed_cases = []\n        \n        for _, row in tqdm(self.instance_coords_df.iterrows(), desc=\"Processing Sagittal T1 images\"):\n            try:\n                # Convert IDs to integers for path construction\n                study_id = str(int(row['study_id']))\n                series_id = str(int(row['series_id']))\n                instance_number = str(int(row['instance_number']))\n                \n                # Construct image path\n                img_path = os.path.join(self.images_dir, study_id, series_id, instance_number)\n                \n                # Try with and without .dcm extension\n                if os.path.exists(img_path + '.dcm'):\n                    img_path = img_path + '.dcm'\n                elif not os.path.exists(img_path):\n                    raise FileNotFoundError(f\"Image not found: {img_path}\")\n                \n                # Read and process image\n                ds = pydicom.dcmread(img_path)\n                image = ds.pixel_array\n                h, w = image.shape\n                \n                # Create annotations\n                annotations = self.create_yolo_annotation(row, w, h)\n                if not annotations:\n                    continue\n                \n                # Prepare image\n                image_normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n                image_resized = cv2.resize(image_normalized, (self.img_size, self.img_size))\n                \n                # Save files\n                is_train = row['study_id'] in train_studies\n                split = 'train' if is_train else 'val'\n                \n                img_filename = f\"{study_id}_{series_id}_{instance_number}.png\"\n                label_filename = f\"{study_id}_{series_id}_{instance_number}.txt\"\n                \n                cv2.imwrite(os.path.join(self.output_dir, split, 'images', img_filename), \n                           image_resized)\n                with open(os.path.join(self.output_dir, split, 'labels', label_filename), 'w') as f:\n                    f.write('\\n'.join(annotations))\n                \n                # Add split information to row\n                row['split'] = split\n                processed_counts[split] += 1\n                \n            except Exception as e:\n                failed_cases.append((study_id, series_id, instance_number, str(e)))\n        \n        print(f\"\\nProcessing Summary:\")\n        print(f\"Training images: {processed_counts['train']}\")\n        print(f\"Validation images: {processed_counts['val']}\")\n        \n        if failed_cases:\n            print(\"\\nFailed cases:\")\n            for case in failed_cases:\n                print(f\"Study {case[0]}, Series {case[1]}, Instance {case[2]}: {case[3]}\")\n        \n        return self.instance_coords_df\n\n    def create_dataset_yaml(self):\n        \"\"\"Create YOLO dataset configuration file\"\"\"\n        yaml_content = {\n            'path': os.path.abspath(self.output_dir),\n            'train': 'train/images',\n            'val': 'val/images',\n            'nc': 5,  # number of classes\n            'names': {\n                0: 'L1/L2',\n                1: 'L2/L3',\n                2: 'L3/L4',\n                3: 'L4/L5',\n                4: 'L5/S1'\n            }\n        }\n\n        yaml_path = os.path.join(self.output_dir, 'dataset.yaml')\n        with open(yaml_path, 'w') as f:\n            yaml.dump(yaml_content, f, sort_keys=False)\n\n        return yaml_path\n\n    def train_yolo(self):\n        \"\"\"Train YOLO model for Sagittal T1 images\"\"\"\n        try:\n            model = YOLO('https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x.pt')\n            \n            config = {\n                'data': self.yaml_path,\n                'imgsz': self.img_size,\n                'batch': 16,\n                'epochs': 100,\n                'patience': 15,\n                'device': '0',\n                'workers': 8,\n                'project': 'spine_detection',\n                'name': 'sagittal_t2_yolo',\n                'exist_ok': True,\n                'pretrained': True,\n                'optimizer': 'AdamW',\n                'verbose': True,\n                'seed': 42,\n                'deterministic': True,\n                'dropout': 0.2,\n                'lr0': 0.001,\n                'lrf': 0.01,\n                'momentum': 0.937,\n                'weight_decay': 0.0005,\n                'warmup_epochs': 10,\n                'warmup_momentum': 0.8,\n                'box': 7.5,\n                'cls': 0.5,\n                'dfl': 1.5,\n                'close_mosaic': 10,\n                'amp': True,\n            }\n            \n            results = model.train(**config)\n            return model, results\n            \n        except Exception as e:\n            print(f\"Error training model: {str(e)}\")\n            return None, None\n\n    def get_training_stats(self):\n        \"\"\"Get statistics about the processed dataset\"\"\"\n        stats = {\n            'total_series': len(self.instance_coords_df['series_id'].unique()),\n            'total_instances': len(self.instance_coords_df),\n            'train_images': len(self.processed_df[self.processed_df['split'] == 'train']),\n            'val_images': len(self.processed_df[self.processed_df['split'] == 'val']),\n            'level_coverage': {}\n        }\n        \n        for level in ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']:\n            count = self.instance_coords_df[f'{level}_center_x'].notna().sum()\n            stats['level_coverage'][level] = {\n                'count': count,\n                'percentage': count/len(self.instance_coords_df)*100\n            }\n            \n        return stats","metadata":{"execution":{"iopub.status.busy":"2024-12-10T10:24:03.478001Z","iopub.execute_input":"2024-12-10T10:24:03.478461Z","iopub.status.idle":"2024-12-10T10:24:03.506918Z","shell.execute_reply.started":"2024-12-10T10:24:03.478424Z","shell.execute_reply":"2024-12-10T10:24:03.506089Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Sagittal T2/STIR\nimages_dir  = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\noutput_dir = '/kaggle/working/spine_dataset_segt2'\n\nsag_t2_model = SagT2_YOLO(\n    df=sagt2_df,\n    images_dir=images_dir,\n    output_dir=output_dir,\n    img_size=384\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-10T10:24:03.507902Z","iopub.execute_input":"2024-12-10T10:24:03.508199Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nDataset Statistics:\nTotal series processed: 1973\nTotal instances processed: 2521\n\nLevel availability:\nl1_l2: 2441 instances (96.8%)\n  - Original: 1903\n  - Shared: 538\nl2_l3: 2478 instances (98.3%)\n  - Original: 1933\n  - Shared: 545\nl3_l4: 2520 instances (100.0%)\n  - Original: 1972\n  - Shared: 548\nl4_l5: 2519 instances (99.9%)\n  - Original: 1971\n  - Shared: 548\nl5_s1: 2517 instances (99.8%)\n  - Original: 1969\n  - Shared: 548\n","output_type":"stream"},{"name":"stderr","text":"Processing Sagittal T1 images: 2521it [00:49, 50.62it/s]","output_type":"stream"},{"name":"stdout","text":"\nProcessing Summary:\nTraining images: 2018\nValidation images: 503\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x.pt to 'weights/yolo11x.pt'...\n","output_type":"stream"},{"name":"stderr","text":"\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 109M/109M [00:00<00:00, 266MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.48 üöÄ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=weights/yolo11x.pt, data=/kaggle/working/spine_dataset_segt2/dataset.yaml, epochs=100, time=None, patience=15, batch=16, imgsz=384, save=True, save_period=-1, cache=False, device=0, workers=8, project=spine_detection, name=sagittal_t2_yolo, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.2, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=10, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=spine_detection/sagittal_t2_yolo\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 44.9MB/s]\n2024-12-10 10:25:06,025\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-12-10 10:25:06,530\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=5\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n 10                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  2   1700352  ultralytics.nn.modules.block.C3k2            [1536, 384, 2, True]          \n 17                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  2   5317632  ultralytics.nn.modules.block.C3k2            [1152, 768, 2, True]          \n 20                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n 23        [16, 19, 22]  1   3151327  ultralytics.nn.modules.head.Detect           [5, [384, 768, 768]]          \nYOLO11x summary: 631 layers, 56,879,551 parameters, 56,879,535 gradients, 195.5 GFLOPs\n\nTransferred 1009/1015 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir spine_detection/sagittal_t2_yolo', view at http://localhost:6006/\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 189MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/spine_dataset_segt2/train/labels... 2018 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2018/2018 [00:02<00:00, 797.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/spine_dataset_segt2/train/labels.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/spine_dataset_segt2/val/labels... 503 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 503/503 [00:00<00:00, 633.63it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/spine_dataset_segt2/val/labels.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to spine_detection/sagittal_t2_yolo/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\nImage sizes 384 train, 384 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mspine_detection/sagittal_t2_yolo\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100      7.51G      2.693      2.558      1.281         14        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:25<00:00,  1.49it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:08<00:00,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481       0.29      0.551      0.316     0.0862\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100      7.16G      2.024      1.425     0.9958         24        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:23<00:00,  1.51it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481       0.66      0.738      0.713      0.242\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/100      7.13G      1.908       1.29     0.9697         20        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:21<00:00,  1.56it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481       0.59      0.664      0.604      0.219\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/100       7.4G      1.942      1.324     0.9747         11        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:21<00:00,  1.56it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.09it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.463      0.692       0.55      0.136\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/100      7.17G      1.931      1.287     0.9652         14        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:21<00:00,  1.56it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.05it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.715      0.685      0.721      0.266\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/100      7.22G      1.869      1.243     0.9592         17        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.692      0.753      0.696      0.208\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/100      7.36G      1.852      1.204      0.951         21        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.453       0.48      0.364     0.0678\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/100      7.25G      1.925      1.234     0.9652         10        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.769      0.886      0.836      0.344\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/100      7.22G      1.794       1.16     0.9432          9        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.834      0.817      0.833      0.332\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/100      7.39G      1.818      1.171     0.9476          8        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.856      0.857      0.859      0.315\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     11/100       7.2G       1.78      1.118     0.9413         11        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.889      0.895      0.895      0.399\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     12/100      7.35G      1.765      1.118     0.9394         24        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.06it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.873      0.878      0.878      0.385\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     13/100      7.21G      1.763      1.107     0.9387         10        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.877       0.89      0.898      0.403\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     14/100      7.38G      1.741      1.094     0.9344          4        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.871      0.879      0.867      0.369\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     15/100      7.37G      1.738      1.058     0.9341          9        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.894      0.886      0.896      0.374\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     16/100      7.36G      1.737      1.056     0.9325          9        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.899      0.884        0.9      0.396\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     17/100      7.41G      1.725      1.071     0.9314          9        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.876      0.885      0.878      0.384\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     18/100      7.42G      1.707      1.041     0.9255         21        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481        0.9      0.906      0.907      0.416\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     19/100       7.2G      1.702      1.064     0.9242         18        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.887      0.885      0.899      0.404\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     20/100      7.19G      1.705      1.053     0.9277         14        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.899      0.906        0.9      0.417\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     21/100      7.39G      1.701      1.011     0.9274         10        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.899      0.896      0.892      0.403\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     22/100      7.38G      1.667      1.031     0.9194         18        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.831      0.854      0.859      0.399\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     23/100      7.21G      1.669      1.017     0.9186         19        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481       0.89      0.896      0.885       0.38\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     24/100      7.19G      1.671     0.9927     0.9229         15        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481       0.87      0.897      0.873      0.389\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     25/100      7.22G      1.651      1.021     0.9179          7        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.904      0.907      0.907      0.428\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     26/100      7.38G      1.656      1.006     0.9171         10        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.909      0.917      0.911      0.421\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     27/100      7.22G      1.645      0.996     0.9164         20        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.09it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.904      0.911       0.91      0.424\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     28/100      7.18G      1.643     0.9822      0.918          5        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.903      0.911      0.905      0.427\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     29/100      7.22G      1.642     0.9836     0.9144          8        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.09it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.907      0.912      0.907       0.41\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     30/100      7.38G      1.635     0.9629      0.916          7        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:20<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.914      0.912      0.914      0.432\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     31/100      7.37G      1.632     0.9647     0.9164         18        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.914      0.918       0.91      0.425\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     32/100      7.35G      1.631     0.9669     0.9157         12        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [01:19<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:07<00:00,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        503       2481      0.907      0.908      0.908      0.424\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     33/100      7.26G      1.623     0.9873     0.9044        115        384:  23%|‚ñà‚ñà‚ñé       | 29/127 [00:18<01:01,  1.59it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def save_trained_model(model, best_model_path, model_type, save_path='/kaggle/working/'):\n    \"\"\"\n    Save the trained YOLO model with simple fixed naming\n    \n    Args:\n        model: YOLO model object\n        best_model_path: Path to the best model weights\n        model_type: String indicating model type ('sag_t1', 'sag_t2', or 'axial_t2')\n        save_path: Base path to save the model\n    \"\"\"\n    # Define simple model names\n    model_names = {\n        'sag_t1': 'sagittal_t1_spine_detector.pt',\n        'sag_t2': 'sagittal_t2_spine_detector.pt',\n        'axial_t2': 'axial_t2_spine_detector.pt'\n    }\n    \n    if model_type not in model_names:\n        raise ValueError(f\"Invalid model_type: {model_type}. Must be one of {list(model_names.keys())}\")\n    \n    try:\n        if not os.path.exists(best_model_path):\n            print(f\"Best model weights not found at {best_model_path}\")\n            return\n            \n        final_save_path = os.path.join(save_path, model_names[model_type])\n        \n        # Copy the model file\n        import shutil\n        shutil.copy(best_model_path, final_save_path)\n        print(f\"Model saved to {final_save_path}\")\n        \n    except Exception as e:\n        print(f\"Error saving model: {str(e)}\")\n\n# Save models with appropriate type\n#save_trained_model(\n#    sag_t1_model.model, \n#    '/kaggle/working/spine_detection/sagittal_t1_yolo/weights/best.pt',\n#    model_type='sag_t1'\n#)\n\nsave_trained_model(\n    sag_t2_model.model, \n    '/kaggle/working/spine_detection/sagittal_t2_yolo/weights/best.pt',\n    model_type='sag_t2'\n)\n\n#save_trained_model(\n#    axial_t2_model.model, \n#    '/kaggle/working/spine_detection/axial_t2_yolo/weights/best.pt',\n#    model_type='axial_t2'\n#)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -r yolov8x.pt\n!rm -r yolo11n.pt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove all the folders execpt the weights\nimport shutil\nshutil.rmtree(\"spine_detection\")\n#shutil.rmtree(\"spine_dataset_sagt1\")\nshutil.rmtree(\"spine_dataset_segt2\")\n#shutil.rmtree(\"spine_dataset_axialt2\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_spine_predictions(image_path, model_path, \n                         conf_threshold=0.25, iou_threshold=0.45, img_size=384):\n    \"\"\"\n    Plot YOLO predictions for spine levels on a DICOM image\n    \n    Args:\n        image_path: Path to DICOM image\n        model_path: Path to saved YOLO model\n        conf_threshold: Confidence threshold for predictions\n        iou_threshold: IOU threshold for NMS\n        img_size: Image size for model input\n    \"\"\"\n    # Load model\n    model = YOLO(model_path)\n    \n    # Read DICOM\n    ds = pydicom.dcmread(image_path)\n    image = ds.pixel_array\n    \n    # Normalize and resize\n    image_normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n    image_resized = cv2.resize(image_normalized, (img_size, img_size))\n    \n    # Convert grayscale to RGB\n    image_rgb = np.stack([image_resized] * 3, axis=-1)\n    \n    # Create figure\n    plt.figure(figsize=(15, 7))\n    \n    # Plot original image\n    plt.subplot(1, 2, 1)\n    plt.imshow(image_resized, cmap='gray')\n    plt.title('Original Image')\n    plt.axis('off')\n    \n    # Plot image with predictions\n    plt.subplot(1, 2, 2)\n    plt.imshow(image_resized, cmap='gray')\n    plt.title('Predictions')\n    \n    # Get predictions\n    results = model.predict(\n        source=image_rgb,\n        conf=conf_threshold,\n        iou=iou_threshold\n    )\n    \n    # Define colors for each level\n    colors = ['red', 'green', 'blue', 'yellow', 'purple']\n    level_names = ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']\n    \n    if results[0].boxes is not None:\n        boxes = results[0].boxes.cpu().numpy()\n        \n        # Sort boxes by y-coordinate to display levels in order\n        box_data = []\n        for box in boxes:\n            cls_id = int(box.cls[0])\n            conf = box.conf[0]\n            x1, y1, x2, y2 = box.xyxy[0]\n            box_data.append((y1, cls_id, conf, x1, y1, x2, y2))\n        \n        box_data.sort()  # Sort by y1 coordinate\n        \n        # Plot each detection\n        for i, (_, cls_id, conf, x1, y1, x2, y2) in enumerate(box_data):\n            color = colors[cls_id]\n            level_name = level_names[cls_id]\n            \n            # Draw bounding box\n            plt.gca().add_patch(plt.Rectangle(\n                (x1, y1), x2-x1, y2-y1,\n                fill=False, color=color, linewidth=2\n            ))\n            \n            # Add label\n            plt.text(\n                x2 + 5, (y1 + y2) / 2, \n                f'{level_name}: {conf:.2f}',\n                color=color, fontsize=8, verticalalignment='center',\n                bbox=dict(facecolor='white', alpha=0.7, edgecolor='none')\n            )\n            \n            # Print detection info\n            print(f\"Found {level_name} with confidence {conf:.2f}\")\n    else:\n        print(\"No detections found\")\n    \n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_multiple_images(image_paths, model_path, \n                          conf_threshold=0.25, iou_threshold=0.45):\n    \"\"\"\n    Process multiple images and display their predictions, skipping images without predictions\n    \n    Args:\n        image_paths: List of paths to DICOM images\n        model_path: Path to saved YOLO model\n        conf_threshold: Confidence threshold for predictions\n        iou_threshold: IOU threshold for NMS\n    \"\"\"\n    # First, filter images that have predictions\n    valid_images = []\n    model = YOLO(model_path)\n    \n    for img_path in image_paths:\n        ds = pydicom.dcmread(img_path)\n        image = ds.pixel_array\n        image_normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n        image_resized = cv2.resize(image_normalized, (384, 384))\n        image_rgb = np.stack([image_resized] * 3, axis=-1)\n        \n        results = model.predict(\n            source=image_rgb,\n            conf=conf_threshold,\n            iou=iou_threshold\n        )\n        \n        if results[0].boxes is not None and len(results[0].boxes) > 0:\n            valid_images.append(img_path)\n    \n    if not valid_images:\n        print(\"No images with valid predictions found\")\n        return\n    \n    # Process only images with predictions\n    for img_path in valid_images:\n        plot_spine_predictions(img_path, model_path, conf_threshold, iou_threshold)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Usage example for Sagittal T2:\nimage_paths = glob.glob('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/4646740/3666319702/*.dcm')\nprocess_multiple_images(image_paths, '/kaggle/working/sagittal_t2_spine_detector.pt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}