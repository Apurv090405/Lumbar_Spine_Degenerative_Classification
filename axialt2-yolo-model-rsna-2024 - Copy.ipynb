{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:37.768588Z",
     "iopub.status.busy": "2024-12-10T06:45:37.768216Z",
     "iopub.status.idle": "2024-12-10T06:45:48.037002Z",
     "shell.execute_reply": "2024-12-10T06:45:48.036130Z",
     "shell.execute_reply.started": "2024-12-10T06:45:37.768530Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.48-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.3.48-py3-none-any.whl (898 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m898.8/898.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.48 ultralytics-thop-2.0.13\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:48.039066Z",
     "iopub.status.busy": "2024-12-10T06:45:48.038779Z",
     "iopub.status.idle": "2024-12-10T06:45:55.473307Z",
     "shell.execute_reply": "2024-12-10T06:45:55.472428Z",
     "shell.execute_reply.started": "2024-12-10T06:45:48.039039Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import cv2\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPyImage, display\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "import yaml\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:55.474785Z",
     "iopub.status.busy": "2024-12-10T06:45:55.474318Z",
     "iopub.status.idle": "2024-12-10T06:45:55.609967Z",
     "shell.execute_reply": "2024-12-10T06:45:55.609249Z",
     "shell.execute_reply.started": "2024-12-10T06:45:55.474756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\n",
    "label_coords_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv')\n",
    "series_desc_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:55.612046Z",
     "iopub.status.busy": "2024-12-10T06:45:55.611759Z",
     "iopub.status.idle": "2024-12-10T06:46:05.758897Z",
     "shell.execute_reply": "2024-12-10T06:46:05.757857Z",
     "shell.execute_reply.started": "2024-12-10T06:45:55.612019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Getting a list of all the study IDs and paths to their images\n",
    "images_dir_path = r'/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\n",
    "study_id_list = os.listdir(images_dir_path)\n",
    "study_id_paths = [(x, f\"{images_dir_path}/{x}\") for x in study_id_list]\n",
    "\n",
    "# Initialize the metadata dictionary\n",
    "meta_df = {}\n",
    "\n",
    "# Process each study and its series\n",
    "for study_id, study_folder_path in study_id_paths:\n",
    "    series_ids = []\n",
    "    series_descriptions = []\n",
    "    \n",
    "    # Get all the series IDs (folders) within the study folder\n",
    "    try:\n",
    "        series_folders = os.listdir(study_folder_path)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Folder not found for study {study_id}. Skipping this study.\")\n",
    "        continue  # Skip this study if the folder doesn't exist\n",
    "\n",
    "    # Process each series in the study folder\n",
    "    for series_id in series_folders:\n",
    "        try:\n",
    "            # Fetch the series description from the dataframe\n",
    "            series_description = series_desc_df[series_desc_df['series_id'] == int(series_id)]['series_description'].iloc[0]\n",
    "        except (IndexError, ValueError):\n",
    "            # Handle cases where series_id is not found in the dataframe or can't be converted to int\n",
    "            series_description = 'Unknown'\n",
    "\n",
    "        # Append series ID and description to the lists\n",
    "        series_ids.append(series_id)\n",
    "        series_descriptions.append(series_description)\n",
    "    \n",
    "    # Add metadata for the current study_id\n",
    "    meta_df[int(study_id)] = {\n",
    "        'folder_path': study_folder_path,\n",
    "        'series_ids': series_ids,\n",
    "        'series_descriptions': series_descriptions\n",
    "    }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:46:05.760676Z",
     "iopub.status.busy": "2024-12-10T06:46:05.760287Z",
     "iopub.status.idle": "2024-12-10T06:46:08.668683Z",
     "shell.execute_reply": "2024-12-10T06:46:08.667914Z",
     "shell.execute_reply.started": "2024-12-10T06:46:05.760639Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>series_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>322.831858</td>\n",
       "      <td>227.964602</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L2/L3</td>\n",
       "      <td>320.571429</td>\n",
       "      <td>295.714286</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L3/L4</td>\n",
       "      <td>323.030303</td>\n",
       "      <td>371.818182</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L4/L5</td>\n",
       "      <td>335.292035</td>\n",
       "      <td>427.327434</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L5/S1</td>\n",
       "      <td>353.415929</td>\n",
       "      <td>483.964602</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>4</td>\n",
       "      <td>Right Neural Foraminal Narrowing</td>\n",
       "      <td>L4/L5</td>\n",
       "      <td>187.961759</td>\n",
       "      <td>251.839388</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>4</td>\n",
       "      <td>Right Neural Foraminal Narrowing</td>\n",
       "      <td>L5/S1</td>\n",
       "      <td>198.240918</td>\n",
       "      <td>285.613767</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>5</td>\n",
       "      <td>Right Neural Foraminal Narrowing</td>\n",
       "      <td>L3/L4</td>\n",
       "      <td>187.227533</td>\n",
       "      <td>210.722753</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>6</td>\n",
       "      <td>Right Neural Foraminal Narrowing</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>194.569790</td>\n",
       "      <td>127.755258</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>6</td>\n",
       "      <td>Right Neural Foraminal Narrowing</td>\n",
       "      <td>L2/L3</td>\n",
       "      <td>191.632887</td>\n",
       "      <td>165.934990</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>11</td>\n",
       "      <td>Left Neural Foraminal Narrowing</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>196.070671</td>\n",
       "      <td>126.021201</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>11</td>\n",
       "      <td>Left Neural Foraminal Narrowing</td>\n",
       "      <td>L4/L5</td>\n",
       "      <td>186.504472</td>\n",
       "      <td>251.592129</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>11</td>\n",
       "      <td>Left Neural Foraminal Narrowing</td>\n",
       "      <td>L5/S1</td>\n",
       "      <td>197.100569</td>\n",
       "      <td>289.457306</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>12</td>\n",
       "      <td>Left Neural Foraminal Narrowing</td>\n",
       "      <td>L2/L3</td>\n",
       "      <td>191.321555</td>\n",
       "      <td>170.120141</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>12</td>\n",
       "      <td>Left Neural Foraminal Narrowing</td>\n",
       "      <td>L3/L4</td>\n",
       "      <td>187.878354</td>\n",
       "      <td>217.245081</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4003253</td>\n",
       "      <td>2448190387</td>\n",
       "      <td>3</td>\n",
       "      <td>Left Subarticular Stenosis</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>179.126448</td>\n",
       "      <td>161.235521</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4003253</td>\n",
       "      <td>2448190387</td>\n",
       "      <td>4</td>\n",
       "      <td>Right Subarticular Stenosis</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>145.288771</td>\n",
       "      <td>158.624642</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4003253</td>\n",
       "      <td>2448190387</td>\n",
       "      <td>11</td>\n",
       "      <td>Left Subarticular Stenosis</td>\n",
       "      <td>L2/L3</td>\n",
       "      <td>180.979730</td>\n",
       "      <td>158.764479</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4003253</td>\n",
       "      <td>2448190387</td>\n",
       "      <td>11</td>\n",
       "      <td>Right Subarticular Stenosis</td>\n",
       "      <td>L2/L3</td>\n",
       "      <td>145.900042</td>\n",
       "      <td>157.096466</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4003253</td>\n",
       "      <td>2448190387</td>\n",
       "      <td>19</td>\n",
       "      <td>Left Subarticular Stenosis</td>\n",
       "      <td>L3/L4</td>\n",
       "      <td>176.037645</td>\n",
       "      <td>157.528958</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    study_id   series_id  instance_number                         condition  \\\n",
       "0    4003253   702807833                8             Spinal Canal Stenosis   \n",
       "1    4003253   702807833                8             Spinal Canal Stenosis   \n",
       "2    4003253   702807833                8             Spinal Canal Stenosis   \n",
       "3    4003253   702807833                8             Spinal Canal Stenosis   \n",
       "4    4003253   702807833                8             Spinal Canal Stenosis   \n",
       "5    4003253  1054713880                4  Right Neural Foraminal Narrowing   \n",
       "6    4003253  1054713880                4  Right Neural Foraminal Narrowing   \n",
       "7    4003253  1054713880                5  Right Neural Foraminal Narrowing   \n",
       "8    4003253  1054713880                6  Right Neural Foraminal Narrowing   \n",
       "9    4003253  1054713880                6  Right Neural Foraminal Narrowing   \n",
       "10   4003253  1054713880               11   Left Neural Foraminal Narrowing   \n",
       "11   4003253  1054713880               11   Left Neural Foraminal Narrowing   \n",
       "12   4003253  1054713880               11   Left Neural Foraminal Narrowing   \n",
       "13   4003253  1054713880               12   Left Neural Foraminal Narrowing   \n",
       "14   4003253  1054713880               12   Left Neural Foraminal Narrowing   \n",
       "15   4003253  2448190387                3        Left Subarticular Stenosis   \n",
       "16   4003253  2448190387                4       Right Subarticular Stenosis   \n",
       "17   4003253  2448190387               11        Left Subarticular Stenosis   \n",
       "18   4003253  2448190387               11       Right Subarticular Stenosis   \n",
       "19   4003253  2448190387               19        Left Subarticular Stenosis   \n",
       "\n",
       "    level           x           y       series_desc  \n",
       "0   L1/L2  322.831858  227.964602  Sagittal T2/STIR  \n",
       "1   L2/L3  320.571429  295.714286  Sagittal T2/STIR  \n",
       "2   L3/L4  323.030303  371.818182  Sagittal T2/STIR  \n",
       "3   L4/L5  335.292035  427.327434  Sagittal T2/STIR  \n",
       "4   L5/S1  353.415929  483.964602  Sagittal T2/STIR  \n",
       "5   L4/L5  187.961759  251.839388       Sagittal T1  \n",
       "6   L5/S1  198.240918  285.613767       Sagittal T1  \n",
       "7   L3/L4  187.227533  210.722753       Sagittal T1  \n",
       "8   L1/L2  194.569790  127.755258       Sagittal T1  \n",
       "9   L2/L3  191.632887  165.934990       Sagittal T1  \n",
       "10  L1/L2  196.070671  126.021201       Sagittal T1  \n",
       "11  L4/L5  186.504472  251.592129       Sagittal T1  \n",
       "12  L5/S1  197.100569  289.457306       Sagittal T1  \n",
       "13  L2/L3  191.321555  170.120141       Sagittal T1  \n",
       "14  L3/L4  187.878354  217.245081       Sagittal T1  \n",
       "15  L1/L2  179.126448  161.235521          Axial T2  \n",
       "16  L1/L2  145.288771  158.624642          Axial T2  \n",
       "17  L2/L3  180.979730  158.764479          Axial T2  \n",
       "18  L2/L3  145.900042  157.096466          Axial T2  \n",
       "19  L3/L4  176.037645  157.528958          Axial T2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_desc(df, meta_df):\n",
    "    df['series_desc'] = None\n",
    "\n",
    "    # Iterate over rows in the dataframe\n",
    "    for idx, coor_row in df.iterrows():\n",
    "        try:\n",
    "            # Find the meta_df for the study_id\n",
    "            meta_info = meta_df[int(coor_row['study_id'])]\n",
    "\n",
    "            # Find the index of the series_id in the meta_info\n",
    "            series_index = meta_info['series_ids'].index(str(coor_row['series_id']))\n",
    "\n",
    "            # Get the corresponding series description\n",
    "            series_desc = meta_info['series_descriptions'][series_index]\n",
    "\n",
    "            # Update the series_desc column\n",
    "            df.at[idx, 'series_desc'] = series_desc\n",
    "\n",
    "        except KeyError:\n",
    "            print(f\"Error processing study_id: {coor_row['study_id']} - Study ID not found in meta_df\")\n",
    "            df.at[idx, 'series_desc'] = 'Unknown'\n",
    "        except ValueError:\n",
    "            print(f\"Error processing study_id: {coor_row['study_id']} - Series ID not found in meta_df\")\n",
    "            df.at[idx, 'series_desc'] = 'Unknown'\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing study_id: {coor_row['study_id']} - {e}\")\n",
    "            df.at[idx, 'series_desc'] = 'Unknown'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "coords_with_desc = label_coords_df.copy()\n",
    "coords_with_desc = add_desc(coords_with_desc, meta_df)\n",
    "coords_with_desc.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:46:08.670290Z",
     "iopub.status.busy": "2024-12-10T06:46:08.669897Z",
     "iopub.status.idle": "2024-12-10T06:46:08.695688Z",
     "shell.execute_reply": "2024-12-10T06:46:08.694712Z",
     "shell.execute_reply.started": "2024-12-10T06:46:08.670239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sagt1_df = coords_with_desc[coords_with_desc['series_desc'] == 'Sagittal T1'].copy()\n",
    "sagt2_df = coords_with_desc[coords_with_desc['series_desc'] == 'Sagittal T2/STIR'].copy()\n",
    "axialt2_df = coords_with_desc[coords_with_desc['series_desc'] == 'Axial T2'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T07:13:51.100606Z",
     "iopub.status.busy": "2024-12-10T07:13:51.100247Z",
     "iopub.status.idle": "2024-12-10T07:13:51.123471Z",
     "shell.execute_reply": "2024-12-10T07:13:51.122605Z",
     "shell.execute_reply.started": "2024-12-10T07:13:51.100575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AxialT2_YOLO:\n",
    "    def __init__(self, df, images_dir, output_dir, img_size=384):\n",
    "        \"\"\"\n",
    "        Initialize Axial T2 YOLO detector\n",
    "        Args:\n",
    "            df: DataFrame with annotations\n",
    "            images_dir: Path to DICOM images\n",
    "            output_dir: Path to save processed dataset\n",
    "            img_size: Target image size for YOLO\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.images_dir = images_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Create initial directory structure\n",
    "        self.create_dataset_structure()\n",
    "        \n",
    "        # Process dataset\n",
    "        self.processed_records = self.process_instance_coordinates()\n",
    "        self.processed_df = self.process_spine_dataset()\n",
    "        \n",
    "        # Create YAML and train model\n",
    "        self.yaml_path = self.create_dataset_yaml()\n",
    "        self.model, self.results = self.train_yolo()\n",
    "\n",
    "    def create_dataset_structure(self):\n",
    "        \"\"\"Create YOLO dataset directory structure\"\"\"\n",
    "        for split in ['train', 'val']:\n",
    "            for subdir in ['images', 'labels']:\n",
    "                path = os.path.join(self.output_dir, split, subdir)\n",
    "                os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    def process_instance_coordinates(self):\n",
    "        \"\"\"\n",
    "        Process coordinates for Axial images, creating separate records for each level\n",
    "        that has both left and right coordinates\n",
    "        Returns list of records with coordinates for each complete level\n",
    "        \"\"\"\n",
    "        result_records = []\n",
    "\n",
    "        # Group by instance to process each image separately\n",
    "        for (study_id, series_id, instance_number), instance_data in self.df.groupby(['study_id', 'series_id', 'instance_number']):\n",
    "            # Process each level separately\n",
    "            levels_data = {}\n",
    "            \n",
    "            for _, row in instance_data.iterrows():\n",
    "                level = row['level']\n",
    "                condition = row['condition']\n",
    "                x, y = row['x'], row['y']\n",
    "                \n",
    "                if level not in levels_data:\n",
    "                    levels_data[level] = {'left': None, 'right': None}\n",
    "                \n",
    "                if 'Left' in condition:\n",
    "                    levels_data[level]['left'] = (x, y)\n",
    "                elif 'Right' in condition:\n",
    "                    levels_data[level]['right'] = (x, y)\n",
    "            \n",
    "            # Only create records for levels with both coordinates\n",
    "            for level, coords in levels_data.items():\n",
    "                if coords['left'] is not None and coords['right'] is not None:\n",
    "                    record = {\n",
    "                        'study_id': study_id,\n",
    "                        'series_id': series_id,\n",
    "                        'instance_number': instance_number,\n",
    "                        'level': level,\n",
    "                        'left_coord': coords['left'],\n",
    "                        'right_coord': coords['right']\n",
    "                    }\n",
    "                    result_records.append(record)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nDataset Statistics:\")\n",
    "        total_complete = len(result_records)\n",
    "        \n",
    "        print(f\"Total complete level pairs: {total_complete}\")\n",
    "        print(\"\\nBy level statistics:\")\n",
    "        \n",
    "        for level in ['L1/L2', 'L2/L3', 'L3/L4', 'L4/L5', 'L5/S1']:\n",
    "            level_count = sum(1 for r in result_records if r['level'] == level)\n",
    "            if total_complete > 0:\n",
    "                percentage = (level_count / total_complete) * 100\n",
    "            else:\n",
    "                percentage = 0\n",
    "            print(f\"{level}: {level_count} complete pairs ({percentage:.1f}%)\")\n",
    "        \n",
    "        return result_records\n",
    "\n",
    "    def create_yolo_annotation(self, record, image_width, image_height):\n",
    "        \"\"\"\n",
    "        Create YOLO format annotations for a specific level\n",
    "        Returns list of annotations for left and right sides\n",
    "        \"\"\"\n",
    "        annotations = []\n",
    "        box_width = 0.05\n",
    "        box_height = 0.05\n",
    "        \n",
    "        # Both coordinates must be present\n",
    "        x, y = record['left_coord']\n",
    "        x_norm = x / image_width\n",
    "        y_norm = y / image_height\n",
    "        annotations.append(f\"0 {x_norm:.6f} {y_norm:.6f} {box_width:.6f} {box_height:.6f}\")\n",
    "        \n",
    "        x, y = record['right_coord']\n",
    "        x_norm = x / image_width\n",
    "        y_norm = y / image_height\n",
    "        annotations.append(f\"1 {x_norm:.6f} {y_norm:.6f} {box_width:.6f} {box_height:.6f}\")\n",
    "        \n",
    "        return annotations\n",
    "\n",
    "    def process_spine_dataset(self):\n",
    "        \"\"\"Process and save dataset in YOLO format\"\"\"\n",
    "        # Split studies\n",
    "        studies = set(record['study_id'] for record in self.processed_records)\n",
    "        train_studies, val_studies = train_test_split(list(studies), train_size=0.8, random_state=42)\n",
    "        \n",
    "        processed_counts = {'train': 0, 'val': 0}\n",
    "        failed_cases = []\n",
    "        \n",
    "        for record in tqdm(self.processed_records, desc=\"Processing Axial images\"):\n",
    "            try:\n",
    "                study_id = str(int(record['study_id']))\n",
    "                series_id = str(int(record['series_id']))\n",
    "                instance_number = str(int(record['instance_number']))\n",
    "                level = record['level'].lower().replace('/', '_')\n",
    "                \n",
    "                # Construct image path\n",
    "                img_path = os.path.join(self.images_dir, study_id, series_id, f\"{instance_number}.dcm\")\n",
    "                if not os.path.exists(img_path):\n",
    "                    img_path = os.path.join(self.images_dir, study_id, series_id, instance_number)\n",
    "                    if os.path.exists(img_path + '.dcm'):\n",
    "                        img_path = img_path + '.dcm'\n",
    "                    else:\n",
    "                        raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "                \n",
    "                # Read and process image\n",
    "                ds = pydicom.dcmread(img_path)\n",
    "                image = ds.pixel_array\n",
    "                h, w = image.shape\n",
    "                \n",
    "                # Create annotations\n",
    "                annotations = self.create_yolo_annotation(record, w, h)\n",
    "                \n",
    "                # Prepare image\n",
    "                image_normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "                image_resized = cv2.resize(image_normalized, (self.img_size, self.img_size))\n",
    "                \n",
    "                # Determine split\n",
    "                is_train = record['study_id'] in train_studies\n",
    "                split = 'train' if is_train else 'val'\n",
    "                \n",
    "                # Create unique filenames including level information\n",
    "                base_filename = f\"{study_id}_{series_id}_{instance_number}_{level}\"\n",
    "                img_filename = f\"{base_filename}.png\"\n",
    "                label_filename = f\"{base_filename}.txt\"\n",
    "                \n",
    "                # Save files\n",
    "                cv2.imwrite(os.path.join(self.output_dir, split, 'images', img_filename), \n",
    "                           image_resized)\n",
    "                with open(os.path.join(self.output_dir, split, 'labels', label_filename), 'w') as f:\n",
    "                    f.write('\\n'.join(annotations))\n",
    "                \n",
    "                processed_counts[split] += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                failed_cases.append((study_id, series_id, instance_number, str(e)))\n",
    "        \n",
    "        print(f\"\\nProcessing Summary:\")\n",
    "        print(f\"Training images: {processed_counts['train']}\")\n",
    "        print(f\"Validation images: {processed_counts['val']}\")\n",
    "        \n",
    "        if failed_cases:\n",
    "            print(\"\\nFailed cases:\")\n",
    "            for case in failed_cases:\n",
    "                print(f\"Study {case[0]}, Series {case[1]}, Instance {case[2]}: {case[3]}\")\n",
    "        \n",
    "        return pd.DataFrame(self.processed_records)\n",
    "\n",
    "    def create_dataset_yaml(self):\n",
    "        \"\"\"Create YOLO dataset configuration file\"\"\"\n",
    "        yaml_content = {\n",
    "            'path': os.path.abspath(self.output_dir),\n",
    "            'train': 'train/images',\n",
    "            'val': 'val/images',\n",
    "            'nc': 2,  # number of classes (left and right)\n",
    "            'names': {\n",
    "                0: 'left',\n",
    "                1: 'right'\n",
    "            }\n",
    "        }\n",
    "\n",
    "        yaml_path = os.path.join(self.output_dir, 'dataset.yaml')\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            yaml.dump(yaml_content, f, sort_keys=False)\n",
    "\n",
    "        return yaml_path\n",
    "\n",
    "    def train_yolo(self):\n",
    "        \"\"\"Train YOLO model\"\"\"\n",
    "        try:\n",
    "            model = YOLO('https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x.pt')\n",
    "            \n",
    "            config = {\n",
    "                'data': self.yaml_path,\n",
    "                'imgsz': self.img_size,\n",
    "                'batch': 16,\n",
    "                'epochs': 120,\n",
    "                'patience': 15,\n",
    "                'device': '0',\n",
    "                'workers': 8,\n",
    "                'project': 'spine_detection',\n",
    "                'name': 'axial_t2_yolo',\n",
    "                'exist_ok': True,\n",
    "                'pretrained': True,\n",
    "                'optimizer': 'AdamW',\n",
    "                'verbose': True,\n",
    "                'seed': 42,\n",
    "                'deterministic': True,\n",
    "                'dropout': 0.2,\n",
    "                'lr0': 0.001,\n",
    "                'lrf': 0.01,\n",
    "                'momentum': 0.937,\n",
    "                'weight_decay': 0.0005,\n",
    "                'warmup_epochs': 10,\n",
    "                'warmup_momentum': 0.8,\n",
    "                'box': 7.5,\n",
    "                'cls': 0.5,\n",
    "                'dfl': 1.5,\n",
    "                'close_mosaic': 10,\n",
    "                'amp': True\n",
    "            }\n",
    "            \n",
    "            results = model.train(**config)\n",
    "            return model, results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training model: {str(e)}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T07:13:51.636317Z",
     "iopub.status.busy": "2024-12-10T07:13:51.635989Z",
     "iopub.status.idle": "2024-12-10T09:58:40.567081Z",
     "shell.execute_reply": "2024-12-10T09:58:40.565914Z",
     "shell.execute_reply.started": "2024-12-10T07:13:51.636283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics:\n",
      "Total complete level pairs: 5459\n",
      "\n",
      "By level statistics:\n",
      "L1/L2: 1046 complete pairs (19.2%)\n",
      "L2/L3: 1116 complete pairs (20.4%)\n",
      "L3/L4: 1122 complete pairs (20.6%)\n",
      "L4/L5: 1094 complete pairs (20.0%)\n",
      "L5/S1: 1081 complete pairs (19.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Axial images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5459/5459 [00:58<00:00, 93.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Summary:\n",
      "Training images: 4332\n",
      "Validation images: 1127\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x.pt to 'weights/yolo11x.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 109M/109M [00:00<00:00, 394MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.48 üöÄ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=weights/yolo11x.pt, data=/kaggle/working/spine_dataset_axialt2/dataset.yaml, epochs=120, time=None, patience=15, batch=16, imgsz=384, save=True, save_period=-1, cache=False, device=0, workers=8, project=spine_detection, name=axial_t2_yolo, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.2, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=10, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=spine_detection/axial_t2_yolo\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 41.7MB/s]\n",
      "2024-12-10 07:14:55,362\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-12-10 07:14:55,860\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n",
      " 10                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2   1700352  ultralytics.nn.modules.block.C3k2            [1536, 384, 2, True]          \n",
      " 17                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   5317632  ultralytics.nn.modules.block.C3k2            [1152, 768, 2, True]          \n",
      " 20                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 23        [16, 19, 22]  1   3147862  ultralytics.nn.modules.head.Detect           [2, [384, 768, 768]]          \n",
      "YOLO11x summary: 631 layers, 56,876,086 parameters, 56,876,070 gradients, 195.5 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir spine_detection/axial_t2_yolo', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 181MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/spine_dataset_axialt2/train/labels... 4332 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4332/4332 [00:05<00:00, 836.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/spine_dataset_axialt2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/spine_dataset_axialt2/val/labels... 1127 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1127/1127 [00:01<00:00, 860.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/spine_dataset_axialt2/val/labels.cache\n",
      "Plotting labels to spine_detection/axial_t2_yolo/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 384 train, 384 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mspine_detection/axial_t2_yolo\u001b[0m\n",
      "Starting training for 120 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/120       7.4G      2.318      2.035      1.103         30        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [03:01<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:17<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.592      0.601      0.565      0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/120      7.26G      1.981      1.506     0.9904         37        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:59<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.534      0.663      0.607      0.221\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/120      7.27G      1.876       1.44     0.9681         25        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:54<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.597      0.705      0.686       0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/120       7.3G       1.86      1.434     0.9608         37        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:55<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.513       0.67      0.655      0.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/120      7.09G      1.851      1.429     0.9574         25        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:54<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.662      0.609      0.698      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/120      7.16G      1.769      1.407     0.9441         36        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:52<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.582      0.671      0.675      0.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/120      7.09G      1.756      1.399     0.9395         35        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:52<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.713      0.725      0.764      0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/120      7.14G      1.761      1.379     0.9379         27        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:52<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.684       0.69      0.752      0.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/120      7.14G      1.743      1.362     0.9357         23        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:52<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.506      0.713      0.625      0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/120      7.27G      1.712      1.322     0.9271         28        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.507      0.619      0.587      0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/120      7.09G      1.703      1.323      0.928         35        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.741      0.717      0.799      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/120      7.27G      1.688       1.32      0.926         32        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.711      0.702      0.765      0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/120      7.14G       1.69      1.315     0.9226         29        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.474      0.683      0.578      0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/120      7.26G      1.654      1.277     0.9183         48        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.637      0.701       0.73       0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/120       7.3G      1.662      1.278     0.9214         33        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.726      0.753      0.799      0.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/120      7.17G       1.65      1.272     0.9142         33        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.717       0.75      0.782      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/120      7.27G      1.634      1.241     0.9138         28        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:17<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.743      0.731      0.793      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/120      7.09G      1.641      1.245     0.9177         40        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.699       0.72      0.785       0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/120       7.1G      1.626      1.261     0.9152         27        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.688      0.735      0.758      0.353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/120      7.29G      1.619      1.239      0.914         42        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.685      0.675      0.756      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/120      7.32G      1.625      1.218     0.9143         34        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.728      0.719       0.78       0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/120       7.1G      1.611      1.217     0.9137         31        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254        0.7      0.692      0.721       0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/120      7.26G      1.602      1.218     0.9085         41        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.646      0.752       0.78      0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/120      7.27G      1.612      1.194     0.9111         24        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.649      0.775      0.771      0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/120      7.27G      1.592      1.196     0.9097         37        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.654      0.711      0.751      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/120       7.1G      1.603      1.204     0.9106         38        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.683      0.709      0.759      0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/120      7.09G      1.609      1.215     0.9098         34        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.731       0.71      0.796      0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/120      7.14G       1.59      1.199     0.9095         21        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.719      0.729      0.781      0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/120      7.27G      1.601      1.195     0.9058         27        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.747      0.743      0.797      0.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/120       7.1G      1.598      1.188     0.9076         34        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.693      0.671      0.761      0.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/120      7.29G      1.589      1.192     0.9073         50        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.704      0.747      0.802      0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/120      7.27G      1.588      1.178     0.9018         18        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254       0.69      0.758      0.791      0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/120      7.26G      1.579      1.171     0.9062         32        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:17<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.712      0.705      0.782      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/120      7.27G      1.557       1.16     0.8993         24        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.652      0.804      0.799      0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/120      7.09G      1.574      1.174     0.9086         32        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254        0.8      0.771      0.842      0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/120       7.3G      1.574      1.166     0.9054         46        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:17<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.742      0.766      0.821       0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/120      7.27G      1.571      1.168     0.9063         34        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.739      0.683      0.772      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/120      7.09G      1.559      1.162     0.9035         41        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254       0.72       0.74      0.794      0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/120       7.1G      1.563      1.156      0.902         24        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:17<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254       0.74      0.703       0.79      0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/120      7.28G      1.569      1.157     0.9053         42        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.744       0.75       0.81      0.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/120      7.26G      1.558      1.149     0.8995         36        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:17<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.611      0.732       0.74      0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/120      7.09G       1.54      1.126     0.9004         48        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.665      0.776       0.79      0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/120      7.26G      1.555      1.142     0.9052         27        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.731      0.768      0.814      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/120      7.13G      1.562      1.142     0.9027         20        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254       0.69      0.722      0.784      0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/120      7.27G      1.559      1.137     0.9006         34        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254       0.74      0.684      0.783      0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/120      7.09G       1.54      1.135     0.8997         34        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.708      0.707      0.758      0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/120      7.25G      1.542      1.128     0.9001         38        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.728      0.717      0.787      0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/120      7.11G      1.534      1.123     0.8996         31        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.758      0.773      0.809      0.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/120      7.27G      1.535      1.102     0.9006         41        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.734      0.721      0.779      0.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/120      7.25G      1.533      1.095     0.9005         36        384: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271/271 [02:51<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:16<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254      0.717      0.746      0.798      0.387\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 36, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "51 epochs completed in 2.714 hours.\n",
      "Optimizer stripped from spine_detection/axial_t2_yolo/weights/last.pt, 114.4MB\n",
      "Optimizer stripped from spine_detection/axial_t2_yolo/weights/best.pt, 114.4MB\n",
      "\n",
      "Validating spine_detection/axial_t2_yolo/weights/best.pt...\n",
      "Ultralytics 8.3.48 üöÄ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "YOLO11x summary (fused): 464 layers, 56,829,334 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:17<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1127       2254        0.8      0.771      0.842      0.398\n",
      "                  left       1127       1127      0.828      0.761      0.858      0.409\n",
      "                 right       1127       1127      0.772      0.781      0.825      0.387\n",
      "Speed: 0.1ms preprocess, 12.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mspine_detection/axial_t2_yolo\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Axial T2\n",
    "images_dir  = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\n",
    "output_dir = '/kaggle/working/spine_dataset_axialt2'\n",
    "\n",
    "axial_t2_model = AxialT2_YOLO(\n",
    "    df=axialt2_df,\n",
    "    images_dir=images_dir,\n",
    "    output_dir=output_dir,\n",
    "    img_size=384\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T09:59:48.649024Z",
     "iopub.status.busy": "2024-12-10T09:59:48.648716Z",
     "iopub.status.idle": "2024-12-10T09:59:48.821118Z",
     "shell.execute_reply": "2024-12-10T09:59:48.820381Z",
     "shell.execute_reply.started": "2024-12-10T09:59:48.648989Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /kaggle/working/axial_t2_spine_detector.pt\n"
     ]
    }
   ],
   "source": [
    "def save_trained_model(model, best_model_path, model_type, save_path='/kaggle/working/'):\n",
    "    \"\"\"\n",
    "    Save the trained YOLO model with simple fixed naming\n",
    "    \n",
    "    Args:\n",
    "        model: YOLO model object\n",
    "        best_model_path: Path to the best model weights\n",
    "        model_type: String indicating model type ('sag_t1', 'sag_t2', or 'axial_t2')\n",
    "        save_path: Base path to save the model\n",
    "    \"\"\"\n",
    "    # Define simple model names\n",
    "    model_names = {\n",
    "        'sag_t1': 'sagittal_t1_spine_detector.pt',\n",
    "        'sag_t2': 'sagittal_t2_spine_detector.pt',\n",
    "        'axial_t2': 'axial_t2_spine_detector.pt'\n",
    "    }\n",
    "    \n",
    "    if model_type not in model_names:\n",
    "        raise ValueError(f\"Invalid model_type: {model_type}. Must be one of {list(model_names.keys())}\")\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(best_model_path):\n",
    "            print(f\"Best model weights not found at {best_model_path}\")\n",
    "            return\n",
    "            \n",
    "        final_save_path = os.path.join(save_path, model_names[model_type])\n",
    "        \n",
    "        # Copy the model file\n",
    "        import shutil\n",
    "        shutil.copy(best_model_path, final_save_path)\n",
    "        print(f\"Model saved to {final_save_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {str(e)}\")\n",
    "\n",
    "Save models with appropriate type\n",
    "save_trained_model(\n",
    "   sag_t1_model.model, \n",
    "   '/kaggle/working/spine_detection/sagittal_t1_yolo/weights/best.pt',\n",
    "   model_type='sag_t1'\n",
    ")\n",
    "\n",
    "save_trained_model(\n",
    "   sag_t2_model.model, \n",
    "   '/kaggle/working/spine_detection/sagittal_t2_yolo/weights/best.pt',\n",
    "   model_type='sag_t2'\n",
    ")\n",
    "\n",
    "save_trained_model(\n",
    "    axial_t2_model.model, \n",
    "    '/kaggle/working/spine_detection/axial_t2_yolo/weights/best.pt',\n",
    "    model_type='axial_t2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T09:59:48.822325Z",
     "iopub.status.busy": "2024-12-10T09:59:48.822051Z",
     "iopub.status.idle": "2024-12-10T09:59:49.932854Z",
     "shell.execute_reply": "2024-12-10T09:59:49.931774Z",
     "shell.execute_reply.started": "2024-12-10T09:59:48.822298Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'yolo11n.pt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r yolo11n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:00:55.933681Z",
     "iopub.status.busy": "2024-12-10T10:00:55.932974Z",
     "iopub.status.idle": "2024-12-10T10:00:55.940629Z",
     "shell.execute_reply": "2024-12-10T10:00:55.939626Z",
     "shell.execute_reply.started": "2024-12-10T10:00:55.933651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Function to plot training and validation loss and accuracy\n",
    "def plot_training_results(results):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss and metrics.\n",
    "\n",
    "    Args:\n",
    "        results: Training results object containing metrics (e.g., results.history)\n",
    "    \"\"\"\n",
    "    if results is None:\n",
    "        print(\"No training results available to plot.\")\n",
    "        return\n",
    "\n",
    "    epochs = range(1, len(results['train_loss']) + 1)\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, results['train_loss'], label='Train Loss')\n",
    "    plt.plot(epochs, results['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Metrics (Accuracy or F1-Score)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, results['train_accuracy'], label='Train Accuracy')\n",
    "    plt.plot(epochs, results['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:00:58.534664Z",
     "iopub.status.busy": "2024-12-10T10:00:58.533832Z",
     "iopub.status.idle": "2024-12-10T10:00:58.545080Z",
     "shell.execute_reply": "2024-12-10T10:00:58.544013Z",
     "shell.execute_reply.started": "2024-12-10T10:00:58.534630Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_axial_predictions(image_path, model_path='axial_t2_spine_detector.pt', \n",
    "                         conf_threshold=0.25, iou_threshold=0.45, img_size=384):\n",
    "    \"\"\"\n",
    "    Plot YOLO predictions for axial images showing left and right sides\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to DICOM image\n",
    "        model_path: Path to saved YOLO model\n",
    "        conf_threshold: Confidence threshold for predictions\n",
    "        iou_threshold: IOU threshold for NMS\n",
    "        img_size: Image size for model input\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Read DICOM\n",
    "    ds = pydicom.dcmread(image_path)\n",
    "    image = ds.pixel_array\n",
    "    \n",
    "    # Normalize and resize\n",
    "    image_normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    image_resized = cv2.resize(image_normalized, (img_size, img_size))\n",
    "    \n",
    "    # Convert grayscale to RGB\n",
    "    image_rgb = np.stack([image_resized] * 3, axis=-1)\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    \n",
    "    # Plot original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_resized, cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot image with predictions\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image_resized, cmap='gray')\n",
    "    plt.title('Predictions')\n",
    "    \n",
    "    # Get predictions\n",
    "    results = model.predict(\n",
    "        source=image_rgb,\n",
    "        conf=conf_threshold,\n",
    "        iou=iou_threshold\n",
    "    )\n",
    "    \n",
    "    # Define colors and names for left/right sides\n",
    "    side_colors = {'left': 'red', 'right': 'blue'}\n",
    "    side_names = {0: 'Left', 1: 'Right'}\n",
    "    \n",
    "    if results[0].boxes is not None:\n",
    "        boxes = results[0].boxes.cpu().numpy()\n",
    "        \n",
    "        # Sort boxes by x-coordinate (left to right)\n",
    "        box_data = []\n",
    "        for box in boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = box.conf[0]\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            box_data.append((x1, cls_id, conf, x1, y1, x2, y2))\n",
    "        \n",
    "        box_data.sort()  # Sort by x1 coordinate\n",
    "        \n",
    "        # Plot each detection\n",
    "        for i, (_, cls_id, conf, x1, y1, x2, y2) in enumerate(box_data):\n",
    "            color = side_colors['left'] if cls_id == 0 else side_colors['right']\n",
    "            side_name = side_names[cls_id]\n",
    "            \n",
    "            # Draw bounding box\n",
    "            plt.gca().add_patch(plt.Rectangle(\n",
    "                (x1, y1), x2-x1, y2-y1,\n",
    "                fill=False, color=color, linewidth=2\n",
    "            ))\n",
    "            \n",
    "            # Add label\n",
    "            plt.text(\n",
    "                x2 + 5, (y1 + y2) / 2, \n",
    "                f'{side_name}: {conf:.2f}',\n",
    "                color=color, fontsize=8, verticalalignment='center',\n",
    "                bbox=dict(facecolor='white', alpha=0.7, edgecolor='none')\n",
    "            )\n",
    "            \n",
    "            # Print detection info\n",
    "            print(f\"Found {side_name} side with confidence {conf:.2f}\")\n",
    "    else:\n",
    "        print(\"No detections found\")\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:20:13.351796Z",
     "iopub.status.busy": "2024-12-10T10:20:13.351442Z",
     "iopub.status.idle": "2024-12-10T10:20:28.812445Z",
     "shell.execute_reply": "2024-12-10T10:20:28.811450Z",
     "shell.execute_reply.started": "2024-12-10T10:20:13.351766Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 1 left, 322.4ms\n",
      "Speed: 2.7ms preprocess, 322.4ms inference, 10.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/12.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 267.8ms\n",
      "Speed: 0.7ms preprocess, 267.8ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/18.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 270.3ms\n",
      "Speed: 1.1ms preprocess, 270.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/9.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 2 lefts, 1 right, 254.6ms\n",
      "Speed: 0.9ms preprocess, 254.6ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/22.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 269.4ms\n",
      "Speed: 0.6ms preprocess, 269.4ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/25.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 (no detections), 262.8ms\n",
      "Speed: 0.6ms preprocess, 262.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Processed and saved: /kaggle/working/predicted_images/39.dcm_predicted.png\n",
      "\n",
      "0: 224x224 (no detections), 261.2ms\n",
      "Speed: 0.7ms preprocess, 261.2ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Processed and saved: /kaggle/working/predicted_images/45.dcm_predicted.png\n",
      "\n",
      "0: 224x224 1 left, 1 right, 250.6ms\n",
      "Speed: 0.7ms preprocess, 250.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/14.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 216.7ms\n",
      "Speed: 0.5ms preprocess, 216.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/11.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 (no detections), 249.1ms\n",
      "Speed: 0.8ms preprocess, 249.1ms inference, 0.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Processed and saved: /kaggle/working/predicted_images/44.dcm_predicted.png\n",
      "\n",
      "0: 224x224 1 left, 235.6ms\n",
      "Speed: 0.5ms preprocess, 235.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/24.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 227.1ms\n",
      "Speed: 0.5ms preprocess, 227.1ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/34.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 2 lefts, 1 right, 240.8ms\n",
      "Speed: 0.5ms preprocess, 240.8ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/29.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 2 rights, 223.7ms\n",
      "Speed: 0.5ms preprocess, 223.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/23.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 right, 224.3ms\n",
      "Speed: 0.7ms preprocess, 224.3ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/41.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 227.4ms\n",
      "Speed: 0.5ms preprocess, 227.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/35.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 240.1ms\n",
      "Speed: 0.7ms preprocess, 240.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/10.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 (no detections), 224.9ms\n",
      "Speed: 0.5ms preprocess, 224.9ms inference, 0.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Processed and saved: /kaggle/working/predicted_images/46.dcm_predicted.png\n",
      "\n",
      "0: 224x224 1 left, 2 rights, 225.7ms\n",
      "Speed: 0.5ms preprocess, 225.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/28.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 (no detections), 221.5ms\n",
      "Speed: 0.8ms preprocess, 221.5ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Processed and saved: /kaggle/working/predicted_images/43.dcm_predicted.png\n",
      "\n",
      "0: 224x224 1 right, 239.0ms\n",
      "Speed: 0.8ms preprocess, 239.0ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/37.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 223.3ms\n",
      "Speed: 0.5ms preprocess, 223.3ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/17.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 216.6ms\n",
      "Speed: 0.7ms preprocess, 216.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/30.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 right, 217.4ms\n",
      "Speed: 0.5ms preprocess, 217.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/1.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 2 rights, 216.2ms\n",
      "Speed: 0.7ms preprocess, 216.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/15.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 213.3ms\n",
      "Speed: 0.7ms preprocess, 213.3ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/2.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 234.3ms\n",
      "Speed: 0.4ms preprocess, 234.3ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/36.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 right, 227.1ms\n",
      "Speed: 0.5ms preprocess, 227.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/8.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 right, 246.3ms\n",
      "Speed: 0.5ms preprocess, 246.3ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/7.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 2 lefts, 1 right, 238.9ms\n",
      "Speed: 0.5ms preprocess, 238.9ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/21.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 231.9ms\n",
      "Speed: 0.5ms preprocess, 231.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/33.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 (no detections), 263.8ms\n",
      "Speed: 0.6ms preprocess, 263.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Processed and saved: /kaggle/working/predicted_images/5.dcm_predicted.png\n",
      "\n",
      "0: 224x224 1 right, 281.7ms\n",
      "Speed: 0.7ms preprocess, 281.7ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/4.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 (no detections), 263.7ms\n",
      "Speed: 0.6ms preprocess, 263.7ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Processed and saved: /kaggle/working/predicted_images/42.dcm_predicted.png\n",
      "\n",
      "0: 224x224 (no detections), 257.4ms\n",
      "Speed: 0.6ms preprocess, 257.4ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Processed and saved: /kaggle/working/predicted_images/47.dcm_predicted.png\n",
      "\n",
      "0: 224x224 1 right, 257.9ms\n",
      "Speed: 0.6ms preprocess, 257.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/31.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 261.8ms\n",
      "Speed: 0.6ms preprocess, 261.8ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/38.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 261.3ms\n",
      "Speed: 0.9ms preprocess, 261.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/19.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 right, 265.2ms\n",
      "Speed: 0.9ms preprocess, 265.2ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/27.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 (no detections), 263.4ms\n",
      "Speed: 0.6ms preprocess, 263.4ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Processed and saved: /kaggle/working/predicted_images/6.dcm_predicted.png\n",
      "\n",
      "0: 224x224 1 left, 2 rights, 266.9ms\n",
      "Speed: 0.6ms preprocess, 266.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/16.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 269.6ms\n",
      "Speed: 0.6ms preprocess, 269.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/20.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 266.6ms\n",
      "Speed: 0.6ms preprocess, 266.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/40.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 264.5ms\n",
      "Speed: 0.6ms preprocess, 264.5ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/3.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 266.7ms\n",
      "Speed: 1.0ms preprocess, 266.7ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/32.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 2 rights, 261.3ms\n",
      "Speed: 0.7ms preprocess, 261.3ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/26.dcm: only one element tensors can be converted to Python scalars\n",
      "\n",
      "0: 224x224 1 left, 1 right, 259.7ms\n",
      "Speed: 0.9ms preprocess, 259.7ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Error processing /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939/3481971518/13.dcm: only one element tensors can be converted to Python scalars\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:19:40.079596Z",
     "iopub.status.busy": "2024-12-10T10:19:40.079182Z",
     "iopub.status.idle": "2024-12-10T10:19:40.084034Z",
     "shell.execute_reply": "2024-12-10T10:19:40.083101Z",
     "shell.execute_reply.started": "2024-12-10T10:19:40.079535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
